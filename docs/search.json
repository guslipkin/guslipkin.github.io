[
  {
    "objectID": "contact.html",
    "href": "contact.html",
    "title": "Contact Me",
    "section": "",
    "text": "Name*\n\n\n\nCompany\n\n\n\nEmail*\n\n\n\nMessage*\n\n\n\n\n Sending this form will take you to an external thank you page\n\n\nSend"
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "My Résumé",
    "section": "",
    "text": "Gus Lipkin\n\n\n\n\n\nFlorida Polytechnic University\n\n\nAug 2018 - May 2022\n\n\n\n– Bachelor of Science, Business Analytics with concentrations in Quantitative Economics & Econometrics and Intelligent Mobility  – Associate of Arts\n\n\nSelected Courses\n\n\n\n\n\n\nDatabase I & II\n\n\n\n\n\n\nStrategic Management\n\n\n\n\n\n\nSix Sigma\n\n\n\n\n\n\nProgramming I\n\n\n\n\n\n\nOperations and Supply Chain & Operations Research\n\n\n\n\n\n\nTime Series Modeling and Forecasting\n\n\n\n\n\n\nStatistics, Quantitative Methods, & Statistical Learning\n\n\n\n\n\n\nBenefit Cost Analysis & Economic Analysis\n\n\n\n\n\n\nSoftware and Programming\n\n\n\n\n\nR and RStudio\n\n\n\n\n\n\nSQL, Redis, Neo4J\n\n\n\n\n\n\nStata\n\n\n\n\n\n\nApache Spark\n\n\n\n\n\n\n\nSoftware Quality Assurance Analyst  – AssistRx\n\n\nJan 2022 - Present\n\n\n\n\nCreate and execute test plans to discover software problems and their causes using qTest and Jira\n\n\nInvestigate patterns in bugs reported using JQL and causal inference\n\n\nDocument and demonstrate software features to internal and external users in Confluence\n\n\n\n\nData Science Project Team Lead  – Tallahassee Memorial Healthcare\n\n\nAug 2021 - Present\n\n\n\n\nCorrelate patient feedback to readmissions and patient experience using linear regression and decision trees\n\n\nCreate a training tool for nurses using significant results found in the analysis\n\n\nWork with capstone sponsor to define project timeline and goals and write a report on project findings\n\n\n\n\nResearch Intern  – iCompBio\n\n\nMay 2021 - Aug 2021\n\n\n\n\nGather and process time series data of geospatial climate variables and SARS-CoV-2 data\n\n\nAnalyze data in R, Excel, and ArcGIS to investigate relationships with time series analysis and linear regressions\n\n\n\n\nData Analyst and Assistant Project Manager  – Draken International\n\n\nDec 2020 - Sep 2021\n\n\n\n\nOversee a team of interns and supervise data migration efforts including cleaning source data before transfer\n\n\nUse text mining and sentiment analysis to correlate jet system failure reports and maintenance repairs\n\n\nCreate and run weekly parts availability analysis and reports using R and RStudio\n\n\n\n\n\nStudent Body Vice-President  – Florida Polytechnic University Student Government Association\n\n\nJan 2022 - Present\n\n\n\n\nAct as the Chief Services Officer of the Student Body\n\n\nAssist the Student Body President in the conduct of government\n\n\nStay in communication with all SGA departments and organizations\n\n\n\n\nDirector of Standards and Enforcement  – Florida Polytechnic University Student Government Association\n\n\nMay 2020 - Jan 2022\n\n\n\n\nManage the SGA SharePoint and CampusLabs\n\n\nTrack SGA and Registered Student Organization assets\n\n\nMaintain FLPolySGA.github.io"
  },
  {
    "objectID": "posts/2022-03-31-pivoting-data-with-tidyverse-and-datatable-in-r.html",
    "href": "posts/2022-03-31-pivoting-data-with-tidyverse-and-datatable-in-r.html",
    "title": "Pivoting Data with tidyverse and datatable in R",
    "section": "",
    "text": "Pivoting data can be a little scary sometimes, even if you know exactly what you want to do. But it doesn’t need to be. I’m hoping that by the end of this post, you’ll feel like the pivot pro you always knew you could be.\n\n\n\n\n\n\n\n(a) A giraffe (longer)\n\n\n\n\n\n\n\n(b) A manta ray (wider)\n\n\n\n\nFigure 1: Longer and wider animals\n\n\n\n\nAs usual, the first thing we want to do is load our libraries. We’ll be using pivot_wider and pivot_longer from tidyverse as well as the pipe operator, %>% from magrittr which is loaded through tidyverse. We’re also using dcast and melt from data.table as they are twins to pivot_wider and pivot_longer, respectively. While they are not identical, they perform the same functions are operate somewhat similarly.\n\nlibrary(tidyverse)\nlibrary(data.table)\n\nNext we want to create our dummy data. I’ve been working with theme park data a lot recently, so I modeled the dummy data after that. The data description is as follows:\n\n\n\n\n\n\n\n\n\nvariable\ntype\ndescription\n\n\n\n\nrideName\ncharacter\nThe full name of the ride\n\n\nshortName\ncharacter\nA shortened version of the name of the ride\n\n\ntime\nITime (from data.table)\nThe time the data was recorded (every 5 minutes from 8am to 5pm)\n\n\nattendance\ndouble\nThe theme park attendance during the time recorded\n\n\nestimatedWait\ndouble\nThe estimated wait time in minutes\n\n\nactualWait\ndouble\nThe actual wait time in minutes\n\n\n\n\n\nset.seed(2022)\nrideName <- rep(c(\"The Amulet from Below\", \"The Strong Key Mystery\",\n                  \"The Punishment of Bane\", \"The Mage Beyond the Grave\",\n                  \"The Fury from Beyond\"), 108)\nshortName <- rep(c(\"amulet\", \"key\", \"punishment\", \"mage\", \"fury\"), 108)\ntime <- as.ITime(rep(seq(8*3600, 17*3600-1, by = 60*5), times = 1, each = 5))\nattendance <- rep(round(rnorm(108, 5000, 100)), times = 1, each = 5)\nestimatedWait <- round(rnorm(length(rideName), 50, 10))\nactualWait <- round(rnorm(length(rideName), estimatedWait, 5))\n\ndt <- data.table(rideName, shortName, time, attendance, estimatedWait, actualWait)\n\nOnce created, the data looks like this:\n\n\n\n\n\n\n\n\n\n\n\n\nrideName\nshortName\ntime\nattendance\nestimatedWait\nactualWait\n\n\n\n\nThe Amulet from Below\namulet\n08:00:00\n5090\n53\n54\n\n\nThe Strong Key Mystery\nkey\n08:00:00\n5090\n62\n64\n\n\nThe Punishment of Bane\npunishment\n08:00:00\n5090\n56\n55\n\n\nThe Mage Beyond the Grave\nmage\n08:00:00\n5090\n40\n33\n\n\nThe Fury from Beyond\nfury\n08:00:00\n5090\n30\n19\n\n\nThe Amulet from Below\namulet\n08:05:00\n4883\n45\n48"
  },
  {
    "objectID": "posts/2022-03-31-pivoting-data-with-tidyverse-and-datatable-in-r.html#pivot_wider-and-dcast",
    "href": "posts/2022-03-31-pivoting-data-with-tidyverse-and-datatable-in-r.html#pivot_wider-and-dcast",
    "title": "Pivoting Data with tidyverse and datatable in R",
    "section": "pivot_wider and dcast",
    "text": "pivot_wider and dcast\npivot_wider and dcast take data and reshapes it so that there are more columns and fewer rows than the input data. It allows you to specify a column as a unique identifier and use the values in one or more columns as new column names. The last column is the values that you want placed in the proper intersection between the identifier column value and each new column value.\n\n\n\n\n\n\n\n(a) The original data\n\n\n\n\n\n\n\n(b) The wider data\n\n\n\n\nFigure 2: Wider data expands columns and decreases length\n\n\nIn the example above, I’ve pivoted the actualWait using the time and shortName columns. We can see that the first five rows of values in actualWait have become the first row of values in the wider data. The last row with The Amulet from Below at 8:05 becomes the value for amulet in the second row of the wider data where the time is 8:05.\nWhile pivot_wider and dcast perform the same function, they behave a little bit differently. pivot_wider uses three main arguments id_cols, names_from, and values_from. dcast, on the other hand, uses a formula argument in place of both id_cols and names_from and value.vars in place of values_from. The second big difference is that column names in pivot_wider don’t have to be in quotes. They can be, but they don’t have to be. On the other hand, only the formula in dcast can go without quotes, and in that case they must not have quotes while value.var must have quotes."
  },
  {
    "objectID": "posts/2022-03-31-pivoting-data-with-tidyverse-and-datatable-in-r.html#pivot_longer-and-melt",
    "href": "posts/2022-03-31-pivoting-data-with-tidyverse-and-datatable-in-r.html#pivot_longer-and-melt",
    "title": "Pivoting Data with tidyverse and datatable in R",
    "section": "pivot_longer and melt",
    "text": "pivot_longer and melt\npivot_longer and melt take data and reshape it so that there are more rows and fewer columns than the input data. It allows you to specify specify columns that you want aggregated and the new column names for what was the column names and the values column.\n\n\n\n\n\n\n\n(a) The original data\n\n\n\n\n\n\n\n(b) The longer data\n\n\n\n\nFigure 3: Longer data combines columns and decreases width\n\n\nIn the example above, the estimatedWait and actualWait columns are consolidated into the waitType column where each row specifies if the corresponding waitTime column is an estimated or actual wait time.\nLike the previous two, pivot_longer and melt have some differences, although these are smaller. pivot_longer uses three primary arguments, cols, names_to, and values_to which correspond to measure.vars, variable.name, and value.name, respectively, from melt. Again, the data.table version, melt requires quotes around each argument value while pivot_longer only requires quotes around names_to and values_to because cols is acting as a select statement."
  },
  {
    "objectID": "posts/2022-03-31-pivoting-data-with-tidyverse-and-datatable-in-r.html#wider-with-one-value-column",
    "href": "posts/2022-03-31-pivoting-data-with-tidyverse-and-datatable-in-r.html#wider-with-one-value-column",
    "title": "Pivoting Data with tidyverse and datatable in R",
    "section": "Wider with One Value Column",
    "text": "Wider with One Value Column\nIn this example, we want to know how long the actualWait is for each ride throughout the day with each recording time as a row, and each ride as a column.\nIn the pivot_wider, we want our new column names_from to be the shortName and our values_from actualWait. The tricky bit here is the id_cols argument. id_cols are columns whose values should uniquely identify each row in the data. We need to use it because the rideName and shortName columns are perfectly correlated, that is, for each row the value of both columns will always be the same. Any column that is not in the names_from or values_from argument will be part of the default id_cols argument. We can use the argument two ways; we can use a numeric vector to select the columns that we want to be used as identifiers, or we can specify columns that we do not want used as a character or column name vector. In the example below, I’ve included both methods. For the rest of the post, I’ll be using the second method.\nAs mentioned previously, the biggest difference for dcast is that it uses a formula instead of the id_cols and names_from arguments. The left hand side of the formula is the columns that you want to stay as columns to be used as the unique identifier for each row. The right hand side of the formula is the column whose values will be used as the new column names. Lastly, value.var defines the column with the desired values.\n\n# pivot wider with one value column\ndt %>% pivot_wider(id_cols = 2:3, \n                   names_from = shortName, \n                   values_from = actualWait)\ndt %>% pivot_wider(id_cols = !c(rideName, attendance, estimatedWait), \n                   names_from = shortName, \n                   values_from = actualWait)\n\ndt %>% dcast(time ~ shortName, \n             value.var = \"actualWait\")\n\n\n\n\n\ntime\namulet\nkey\npunishment\nmage\nfury\n\n\n\n\n08:00:00\n54\n64\n55\n33\n19\n\n\n08:05:00\n48\n54\n40\n56\n55\n\n\n08:10:00\n59\n44\n50\n52\n35\n\n\n08:15:00\n47\n71\n46\n41\n59\n\n\n08:20:00\n26\n68\n64\n47\n48\n\n\n08:25:00\n35\n32\n54\n54\n57"
  },
  {
    "objectID": "posts/2022-03-31-pivoting-data-with-tidyverse-and-datatable-in-r.html#wider-with-two-or-more-value-columns",
    "href": "posts/2022-03-31-pivoting-data-with-tidyverse-and-datatable-in-r.html#wider-with-two-or-more-value-columns",
    "title": "Pivoting Data with tidyverse and datatable in R",
    "section": "Wider with Two or More Value Columns",
    "text": "Wider with Two or More Value Columns\nWider data with more than one value column is very similar to one value column. The only changes you need to make in pivot_wider are changing your id_cols argument if using the column name method and adding the new column to the values_from argument. The only change needed in dcast is adding to the value.var argument. One important thing to note is that the column names will now be a combination of the names_from/right hand side argument and the values_from/value.var argument. The column name order in the value* argument determines the column order in the resulting data.\n\n# pivot wider with two value columns\ndt %>% pivot_wider(id_cols = !c(rideName, attendance), \n                   names_from = shortName, \n                   values_from = c(estimatedWait, actualWait))\n\ndt %>% dcast(time ~ shortName, \n             value.var = c(\"estimatedWait\", \"actualWait\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntime\nestimatedWait_amulet\nestimatedWait_key\nestimatedWait_punishment\nestimatedWait_mage\nestimatedWait_fury\nactualWait_amulet\nactualWait_key\nactualWait_punishment\nactualWait_mage\nactualWait_fury\n\n\n\n\n08:00:00\n53\n62\n56\n40\n30\n54\n64\n55\n33\n19\n\n\n08:05:00\n45\n50\n36\n52\n52\n48\n54\n40\n56\n55\n\n\n08:10:00\n59\n41\n47\n57\n37\n59\n44\n50\n52\n35\n\n\n08:15:00\n45\n61\n47\n32\n62\n47\n71\n46\n41\n59\n\n\n08:20:00\n33\n69\n61\n50\n50\n26\n68\n64\n47\n48\n\n\n08:25:00\n31\n34\n47\n55\n60\n35\n32\n54\n54\n57"
  },
  {
    "objectID": "posts/2022-03-31-pivoting-data-with-tidyverse-and-datatable-in-r.html#pivot-wider-two-or-more-id-columns",
    "href": "posts/2022-03-31-pivoting-data-with-tidyverse-and-datatable-in-r.html#pivot-wider-two-or-more-id-columns",
    "title": "Pivoting Data with tidyverse and datatable in R",
    "section": "Pivot Wider Two or More ID Columns",
    "text": "Pivot Wider Two or More ID Columns\nAgain, this is pretty similar to a “normal” wider operation. With pivot_wider you expand your id_cols to include the new columns, or, in my case, drop the attendance column so that it is now included. With dcast, you simply add the new column to the left hand side of the formula.\n\n# pivot wider with two id columns\ndt %>% pivot_wider(id_cols = !c(rideName, estimatedWait),\n                   names_from = shortName,\n                   values_from = actualWait)\n\ndt %>% dcast(time + attendance ~ shortName,\n             value.var = \"actualWait\")\n\n\n\n\n\ntime\nattendance\namulet\nkey\npunishment\nmage\nfury\n\n\n\n\n08:00:00\n5090\n54\n64\n55\n33\n19\n\n\n08:05:00\n4883\n48\n54\n40\n56\n55\n\n\n08:10:00\n4910\n59\n44\n50\n52\n35\n\n\n08:15:00\n4856\n47\n71\n46\n41\n59\n\n\n08:20:00\n4967\n26\n68\n64\n47\n48\n\n\n08:25:00\n4710\n35\n32\n54\n54\n57"
  },
  {
    "objectID": "posts/2022-03-31-pivoting-data-with-tidyverse-and-datatable-in-r.html#pivot-wider-with-two-or-more-name-columns",
    "href": "posts/2022-03-31-pivoting-data-with-tidyverse-and-datatable-in-r.html#pivot-wider-with-two-or-more-name-columns",
    "title": "Pivoting Data with tidyverse and datatable in R",
    "section": "Pivot Wider with Two or More Name Columns",
    "text": "Pivot Wider with Two or More Name Columns\nWe want to take our new longer data and change it to wider data where we want to know how long the actualWait and estimatedWait are for each ride throughout the day with each recording time as a row, and each ride as a column and waitType and shortName.\nFor pivot_wider, we want our column names to use both the waitType and shortName and our values from waitTime. id_cols is then the remaining columns that we don’t want. With dcast, we want to add waitType and shortName to the right hand side of the formula so they are used as the column names, and time to the left hand side for the row identifiers. For both, values_from and value.var are our waitTime column.\nLike when using multiple values in value_from/value.var, the new column names are all combinations of values in names_from or right hand side. The combinations will be given in the order the column names are specified.\n\n# pivot wider with more than one right hand column\ndtLonger %>% pivot_wider(id_cols = !c(rideName, attendance), \n                         names_from = c(waitType, shortName), \n                         values_from = waitTime)\n\ndtLonger %>% dcast(time ~ waitType + shortName, \n                   value.var = \"waitTime\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntime\nestimatedWait_amulet\nestimatedWait_key\nestimatedWait_punishment\nestimatedWait_mage\nestimatedWait_fury\nactualWait_amulet\nactualWait_key\nactualWait_punishment\nactualWait_mage\nactualWait_fury\n\n\n\n\n08:00:00\n53\n62\n56\n40\n30\n54\n64\n55\n33\n19\n\n\n08:05:00\n45\n50\n36\n52\n52\n48\n54\n40\n56\n55\n\n\n08:10:00\n59\n41\n47\n57\n37\n59\n44\n50\n52\n35\n\n\n08:15:00\n45\n61\n47\n32\n62\n47\n71\n46\n41\n59\n\n\n08:20:00\n33\n69\n61\n50\n50\n26\n68\n64\n47\n48\n\n\n08:25:00\n31\n34\n47\n55\n60\n35\n32\n54\n54\n57"
  },
  {
    "objectID": "posts/2022-03-31-pivoting-data-with-tidyverse-and-datatable-in-r.html#pivot-wider-with-mutiple-id-and-name-columns",
    "href": "posts/2022-03-31-pivoting-data-with-tidyverse-and-datatable-in-r.html#pivot-wider-with-mutiple-id-and-name-columns",
    "title": "Pivoting Data with tidyverse and datatable in R",
    "section": "Pivot Wider with Mutiple ID and Name Columns",
    "text": "Pivot Wider with Mutiple ID and Name Columns\nIf you’ve been following along so far, the code below should make sense. We want to use time and attendance as the row identifiers and the estimatedWait and actualWait as the values for each ride.\n\n# pivot wider with more than one left and right hand column\ndtLonger %>% pivot_wider(id_cols = !rideName, \n                         names_from = c(waitType, shortName), \n                         values_from = waitTime)\n\ndtLonger %>% dcast(time + attendance ~ waitType + shortName, \n                   value.var = \"waitTime\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntime\nattendance\nestimatedWait_amulet\nestimatedWait_key\nestimatedWait_punishment\nestimatedWait_mage\nestimatedWait_fury\nactualWait_amulet\nactualWait_key\nactualWait_punishment\nactualWait_mage\nactualWait_fury\n\n\n\n\n08:00:00\n5090\n53\n62\n56\n40\n30\n54\n64\n55\n33\n19\n\n\n08:05:00\n4883\n45\n50\n36\n52\n52\n48\n54\n40\n56\n55\n\n\n08:10:00\n4910\n59\n41\n47\n57\n37\n59\n44\n50\n52\n35\n\n\n08:15:00\n4856\n45\n61\n47\n32\n62\n47\n71\n46\n41\n59\n\n\n08:20:00\n4967\n33\n69\n61\n50\n50\n26\n68\n64\n47\n48\n\n\n08:25:00\n4710\n31\n34\n47\n55\n60\n35\n32\n54\n54\n57"
  },
  {
    "objectID": "posts/2022-03-31-pivoting-data-with-tidyverse-and-datatable-in-r.html#a-quick-benchmark",
    "href": "posts/2022-03-31-pivoting-data-with-tidyverse-and-datatable-in-r.html#a-quick-benchmark",
    "title": "Pivoting Data with tidyverse and datatable in R",
    "section": "A quick benchmark",
    "text": "A quick benchmark\n\nrbenchmark::benchmark(\n  \"pivot_wider\" = {\n    tmp <- dt %>% pivot_wider(id_cols = !c(rideName, attendance, estimatedWait), \n                              names_from = shortName, \n                              values_from = actualWait)\n  },\n  \"dcast\" = {\n    tmp <- dt %>% dcast(time ~ shortName, \n                        value.var = \"actualWait\")\n  }, order = \"user.self\")\n\nrbenchmark::benchmark(\n  \"pivot_longer\" = {\n    tmp <- dt %>% pivot_longer(cols = c(estimatedWait, actualWait), \n                               names_to = \"waitType\", \n                               values_to = \"waitTime\")\n  },\n  \"melt\" = {\n    tmp <- dt %>% melt(measure.vars = c(\"estimatedWait\", \"actualWait\"),\n                       variable.name = \"waitType\",\n                       value.name = \"waitTime\")\n  }, order = \"user.self\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntest\nreplications\nelapsed\nrelative\nuser.self\nsys.self\nuser.child\nsys.child\n\n\n\n\ndcast\n100\n0.060\n1.00\n0.059\n0.001\n0\n0\n\n\npivot_wider\n100\n0.309\n5.15\n0.307\n0.002\n0\n0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntest\nreplications\nelapsed\nrelative\nuser.self\nsys.self\nuser.child\nsys.child\n\n\n\n\nmelt\n100\n0.005\n1.0\n0.005\n0.000\n0\n0\n\n\npivot_longer\n100\n0.152\n30.4\n0.149\n0.003\n0\n0\n\n\n\n\ndata.table methods are faster than tidyverse and wider to longer is faster than longer to wider."
  },
  {
    "objectID": "posts/2022-03-31-pivoting-data-with-tidyverse-and-datatable-in-r.html#conclusion",
    "href": "posts/2022-03-31-pivoting-data-with-tidyverse-and-datatable-in-r.html#conclusion",
    "title": "Pivoting Data with tidyverse and datatable in R",
    "section": "Conclusion",
    "text": "Conclusion\nI’m hoping that by now you’re more comfortable with pivot_wider/dcast and pivot_longer/melt than you were before. Generally, before you begin reshaping data, you want to know what your resulting data should look like and if you’ll have any duplicate rows. From there, decide if you want to use tidyverse or data.table and then write your code.\n\nAll code used in this article is available here. If you want to see more from me, check out my GitHub or guslipkin.github.io. If you want to hear from me, I’m also on Twitter @guslipkin.\n\nGus Lipkin is a Data Scientist, Business Analyst, and occasional bike mechanic"
  },
  {
    "objectID": "posts/2022-04-14-reordering-bar-and-column-charts-with-ggplot-in-r.html",
    "href": "posts/2022-04-14-reordering-bar-and-column-charts-with-ggplot-in-r.html",
    "title": "Reordering Bar and Column Charts with ggplot2 in R",
    "section": "",
    "text": "Creating the Data\nAs usual, we want to load the tidyverse first since it gives us %>% from magrittr and ggplot2 and everything that comes with it.\n\n\n\nThe dummy data for this post is painting sales. You’re a starving artist who hasn’t taken any days off selling paintings in the past year and you’re trying to start taking a day to yourself every week. Our data has the day of the month (only 28 days per month), the month, the day of the week, and the number of paintings you sold each day. R has a constant built in for the name of the month, month.name, but not one for the days of the week, so we’ll have to make that ourselves. In addition, we start our week on a Sunday.\n\nset.seed(2022)\ndays_of_the_week <- c(\"Sunday\", \"Monday\", \"Tuesday\", \"Wednesday\", \n                      \"Thursday\", \"Friday\", \"Saturday\")\nsales <- data.frame(\"dayOfMonth\" = rep(1:28, 12),\n                    \"month\" = rep(month.name, each = 28),\n                    \"weekday\" = rep(days_of_the_week, 12*4),\n                    \"paintings\" = round(rnorm(28*12, c(sample(1:28, 7)))))\n\nhead(sales, 7)\n\n  dayOfMonth   month   weekday paintings\n1          1 January    Sunday         2\n2          2 January    Monday        20\n3          3 January   Tuesday        13\n4          4 January Wednesday        23\n5          5 January  Thursday        10\n6          6 January    Friday        28\n7          7 January  Saturday         7\n\n\nThe first week’s data shows that we sold the bulk of our paintings on Monday, Wednesday, and Friday, with barely any sales on Sunday and Saturday.\n\n\nGetting the Days in Order\nIn the first chart we make, we want to take the average number of sales per day of the week. To do that, we group_by(weekday) and then summarise the mean(paintings) as a new variable, weekdaySales. In the ggplot chain, we set the chart and axis titles with labs and the color palette with scale_fill_brewer. In aes in geom_bar, we want the weekday on the x axis and weekdaySales on the y axis. To add some color, we set fill = weekday. Outside of the aes but still in geom_bar, we set stat = \"identity\" so that the y axis value is used and show.legend = FALSE to hide the legend.\n\n\n\n\n\n\nNote\n\n\n\nI’ve organized the ggplot() chain so that the items being changed are towards the bottom. The ggplot(), labs(), and scale_fill_brewer() are the same in every example.\nThe only aspects of geom_bar() that will change are the values used for x and y in aes().\n\n\n\nsales %>%\n  group_by(weekday) %>%\n  summarise(weekdaySales = mean(paintings)) %>%\n  ggplot() +\n  labs(title = \"Mean Painting Sales by Day of the Week\",\n       x = \"Day of the Week\",\n       y = \"Mean Painting Sales\") +\n  scale_fill_brewer(palette = \"Set2\") +\n  geom_bar(aes(x = weekday, y = weekdaySales, fill = weekday), \n           stat = \"identity\", show.legend = FALSE)\n\n\n\n\nUnfortunately, our days of the week are not in order. Lots of people would be very sad if Monday came directly after Friday.\n\nsales %>%\n  group_by(weekday) %>%\n  summarise(weekdaySales = mean(paintings)) %>%\n  ggplot() +\n  labs(title = \"Mean Weekly Painting Sales by Day of the Week\",\n       x = \"Day of the Week\",\n       y = \"Mean Painting Sales\") + \n  scale_fill_brewer(palette = \"Set2\") +\n  geom_bar(aes(x = factor(weekday, days_of_the_week), y = weekdaySales, \n               fill = weekday), stat = \"identity\", show.legend = FALSE)\n\n\n\n\nBy changing x = weekday to x = factor(weekday, days_of_the_week), we can get the days in order. The key here is that factor() takes two arguments; a vector of data and a vector defining the levels of the data in order. In this case, days_of_the_week defines the levels in order.\n\n\nAscending or Descending Order\nWhile the graph we just got does the job, we want to see how big the jumps are in order between days of the week. Similarly to getting our days of the week in order, we need to change x = weekday to something else to get our x axis sorted in ascending or descending order. While factor() lets us reorder them by factor levels, reorder allows us to reorder by numeric value. The first argument is the vector we want to change, in this case, weekday, and we want to change it to match the order of the second argument, weekdaySales. In fact, reorder(weekday, weekdaySales) is the same as sales$weekday[order(sales$weekdaySales)].\n\nsales %>%\n  group_by(weekday) %>%\n  summarise(weekdaySales = mean(paintings)) %>%\n  ggplot() +\n  labs(title = \"Mean Weekly Painting Sales in Ascending Order\",\n       x = \"Day of the Week\",\n       y = \"Mean Painting Sales\") + \n  scale_fill_brewer(palette = \"Set2\") +\n  geom_bar(aes(x = reorder(weekday, weekdaySales), y = weekdaySales, \n               fill = weekday), stat = \"identity\", show.legend = FALSE)\n\n\n\n\nThe default order is ascending order, smallest to largest. To reverse the order, we can add a minus sign before the second argument so that it reads reorder(weekday, -weekdaySales).\n\nsales %>%\n  group_by(weekday) %>%\n  summarise(weekdaySales = mean(paintings)) %>%\n  ggplot() +\n  labs(title = \"Mean Weekly Painting Sales in Descending Order\",\n       x = \"Day of the Week\",\n       y = \"Mean Painting Sales\") + \n  scale_fill_brewer(palette = \"Set2\") +\n  geom_bar(aes(x = reorder(weekday, -weekdaySales), y = weekdaySales, \n               fill = weekday), stat = \"identity\", show.legend = FALSE)\n\n\n\n\n\n\nAttempting to Order Within Facets\nBefore we get started on facets, I want to change the data a little so that the examples are a little clearer. By adding some variation into the paintings variable, the differences between days of different months will be more apparent.\n\nsales$paintings <- round(rnorm(28*12, c(sample(1:28, 28*12, replace = TRUE))))\n\nThinking that maybe we’d like to switch up our day off every month, we want to see how our sales change over the course of the year, but still group_by(weekday). However, since we want to know the mean for each weekday for each month, we need to add that so we have group_by(month, weekday). We also add facet_wrap(~ month) to the end of the ggplot chain. Essentially, this means that we want to have a mini plot for each month. In this case, we’ve ordered our y axis so that the days of the week are in order from top to bottom.\n\nsales %>%\n  group_by(month, weekday) %>%\n  summarise(weekdaySales = mean(paintings)) %>%\n  ggplot() +\n  labs(title = \"Daily Painting Sales by Month\",\n       x = \"Mean Painting Sales\",\n       y = \"Day of the Week\") + \n  scale_fill_brewer(palette = \"Set2\") +\n  geom_bar(aes(x = weekdaySales, y = factor(weekday, rev(days_of_the_week)), \n               fill = weekday), stat = \"identity\", show.legend = FALSE) +\n  facet_wrap(~ month)\n\n\n\n\nThat’s all well and good, but what if we want each month ordered in descending order like we had the chart before? We can try changing y = factor() to y = reorder(). We also add scales = \"free_y\" to facet_wrap so that each chart’s y axis is calculated independently. It’s quickly apparent that this doesn’t work the way we were expecting it to. The facets are not sorted properly and all of them are sorted the same way.\n\nsales %>%\n  group_by(month, weekday) %>%\n  summarise(weekdaySales = mean(paintings)) %>%\n  ggplot() +\n  labs(title = \"Daily Painting Sales by Month but not in Descending Order\",\n       x = \"Mean Painting Sales\",\n       y = \"Day of the Week\") + \n  scale_fill_brewer(palette = \"Set2\") +\n  geom_bar(aes(x = weekdaySales, y = reorder(weekday, weekdaySales), \n               fill = weekday), stat = \"identity\", show.legend = FALSE) +\n  facet_wrap(~ month, scales = \"free_y\")\n\n\n\n\nNot sure what happened, we try to investigate. If we re-run the earlier Mean Weekly Painting Sales in Descending Order chart with the new data and grouped by weekday, we find that the y axis in each facet is, in fact, in order with Sunday with the highest sales and Friday with the lowest, but the order hasn’t been recalculated for each month.\n\n\n\n\n\n\n\nOrdering Within Facets\nAs it turns out, there’s a rather simple way to give your facets each their own ordering. The tidytext package provides the functionality with three functions that go hand-in-hand. reorder_within() does the heavy lifting while scale_x_reordered() and scale_y_reordered() make sure that the order set in reorder_within() is respected.\n\n\n\n\n\n\nTip\n\n\n\nJulia Silge writes about reorder_within on her blog here and has some information on its creation and how it came to live in tidytext in the first paragraph of the “Enter reorder_within()” section.\n\n\n\nlibrary(tidytext)\n\nInstead of using factor() and reorder(), we change the y axis argument in aes() to use reorder_within: y = reorder_within(weekday, weekdaySales, month). Our first argument, weekday is the vector we want to reorder. The second argument, weekdaySales is the variable we want to use for reordering. The last argument, month, is the variable we want to use for grouping. The third argument could be a vector of column names if we wanted to group by multiple variables. Like with reorder(), we can set the direction to ascending with a minus sign before the ordering argument, weekdaySales. We keep scales = \"free_y\" in facet_wrap() so that each facet has its own order, and then use scale_y_reordered() to make sure that the new order from reorder_within() is used.\n\nsales %>%\n  group_by(month, weekday) %>%\n  summarise(weekdaySales = mean(paintings)) %>%\n  ggplot() +\n  labs(title = \"Daily Painting Sales in Descending Order by Month\",\n       x = \"Mean Painting Sales\",\n       y = \"Day of the Week\") +\n  scale_fill_brewer(palette = \"Set2\") +\n  geom_bar(aes(x = weekdaySales, \n               y = reorder_within(weekday, weekdaySales, month), \n               fill = weekday), stat = \"identity\", show.legend = FALSE) +\n  facet_wrap(~ month, scales = \"free_y\") +\n  scale_y_reordered()\nsales %>%\n  group_by(month, weekday) %>%\n  summarise(weekdaySales = mean(paintings)) %>%\n  ggplot() +\n  labs(title = \"Daily Painting Sales in Ascending Order by Month\",\n       x = \"Mean Painting Sales\",\n       y = \"Day of the Week\") +\n  scale_fill_brewer(palette = \"Set2\") +\n  geom_bar(aes(x = weekdaySales, \n               y = reorder_within(weekday, -weekdaySales, month), \n               fill = weekday), stat = \"identity\", show.legend = FALSE) +\n  facet_wrap(~ month, scales = \"free_y\") +\n  scale_y_reordered()\n\n\n\n\n\n\n\n\n\n\n\n\n\nOrdering Facets and an Easier Way to Order by Day\nAt this point, you might be staring at your screen in disbelief and thinking, “But Gus, the facets aren’t in order! The months are in alphabetical order and not calendar order!” You’re not wrong. When we were setting the order of y with factor(), we were doing something that we could have done much earlier in our data creation stage. If we redefine the month and weekday variables using the factor(variable, levels) syntax, we don’t need to use y = factor(weekday) to make sure our days are in order. In addition, the facets will now be in calendar order like they appear in the month.name constant. I’ve chosen to reverse the days_of_the_week so that Sunday appears at the top, rather than at the bottom of the y axis.\n\nsales$month <- factor(sales$month, levels = month.name)\nsales$weekday <- factor(sales$weekday, levels = rev(days_of_the_week))\n\nsales %>%\n  group_by(month, weekday) %>%\n  summarise(weekdaySales = mean(paintings)) %>%\n  ggplot() +\n  labs(title = \"Daily Painting Sales in Descending Order by Month\",\n       x = \"Mean Painting Sales\",\n       y = \"Day of the Week\") +\n  scale_fill_brewer(palette = \"Set2\") +\n  geom_bar(aes(x = weekdaySales, y = weekday, fill = weekday), \n           stat = \"identity\", show.legend = FALSE) +\n  facet_wrap(~ month)\n\n\n\n\n\nAll code used in this article is available here. If you want to see more from me, check out my GitHub or guslipkin.github.io. If you want to hear from me, I’m also on Twitter @guslipkin.\n\nGus Lipkin is a Data Scientist, Business Analyst, and occasional bike mechanic"
  },
  {
    "objectID": "posts/2022-03-14-writing-faster-r-with-vectorization-and-the-apply-family.html",
    "href": "posts/2022-03-14-writing-faster-r-with-vectorization-and-the-apply-family.html",
    "title": "Writing Faster R With Vectorization and the Apply Family",
    "section": "",
    "text": "Link to the Medium post"
  },
  {
    "objectID": "posts/2022-03-14-writing-faster-r-with-vectorization-and-the-apply-family.html#for-loop",
    "href": "posts/2022-03-14-writing-faster-r-with-vectorization-and-the-apply-family.html#for-loop",
    "title": "Writing Faster R With Vectorization and the Apply Family",
    "section": "for loop",
    "text": "for loop\nIf you’re familiar with programming, you can probably skip this section.\nA for loop lets you run the same code a specified number of times. The structure generally follows for(x in y) where x represents an item in y. If we think about a shopping basket with some apples, bananas, and carrots, we could write for(food in basket) and food would represent each item in our basket. It would be apples the first time, bananas the second time, and carrots the third time. We could also write it as for(food in 1:length(basket)) where 1:length(basket) is a vector of numbers that counts the items in your basket. Rather than food representing an item in your basket, it represents an index in the vector. In this example, apples are at index 1, bananas at 2, and carrots at 3. for loops are also very flexible and can be used on many data types such as vectors, data.frames, and matrices.\nLet’s say you have a data.frame called basket that has three columns. It has the Food column with the name of the food, the PricePerUnit which has the unit cost for each food, and Quantity which has the number of units of each food in your basket. It looks like this:\n\n\n\nFood\nPricePerUnit\nQuantity\n\n\n\n\nApples\n0.99\n12\n\n\nBananas\n0.19\n6\n\n\nCarrots\n0.49\n2\n\n\n\nAnd it can be recreated with this:\n\nbasket <- data.frame(\"Food\" = c(\"Apples\", \"Bananas\", \"Carrots\"),\n                     \"PricePerUnit\" = c(.99, .19, .49),\n                     \"Quantity\" = c(12, 6, 2))\n\nIf we wanted to get the total cost of everything in our basket, we could iterate over each row multiplying the PricePerUnit and Quantity and adding those to our running totals.\n\n# create the total\ntotal <- 0\n# loop over the data.frame and add the running total\nfor(row in 1:nrow(basket))\n  total <- total + (basket$PricePerUnit[row] * basket$Quantity[row])\ntotal\n\n[1] 14"
  },
  {
    "objectID": "posts/2022-03-14-writing-faster-r-with-vectorization-and-the-apply-family.html#apply-family",
    "href": "posts/2022-03-14-writing-faster-r-with-vectorization-and-the-apply-family.html#apply-family",
    "title": "Writing Faster R With Vectorization and the Apply Family",
    "section": "apply family",
    "text": "apply family\nThe apply family is part of base R and very similar to a for loop. Rather than running a set number of times, an apply runs a function on each item in a data.frame, list, vector, or other object that can be applied to. While there are six different functions in the apply family, I’m only going to talk about the three most common; apply, lapply, and sapply.\nThe biggest differences between the three is the types of input that they accept and their output types. apply takes in a data.frame or matrix and has three function arguments. The first argument, x, is the object we’re passing to it. The second argument is a number, either 1 or 2 or c(1, 2), that says if we want the function applied to rows, columns, or both rows and columns, respectively. The last argument is the function call. sapply and lapply are the same, except they don’t have the second argument because they take either a vector or list which don’t have multiple dimensions. Generally speaking, the apply family will return a vector, list, or array of some kind.\nIf we go back to the shopping basket example, we can calculate the total with an apply function. Our first argument is the basket, the second is a 1 because we want to apply to every row, and the last is the function call. We can create the function in the apply call or we can create it earlier and then call it here.\n\n# multiply each PricePerUnit and Quantity and store the resulting vector\nperItemTotal <- apply(basket, 1, function(bskt) {\n  as.numeric(bskt[\"PricePerUnit\"]) * as.numeric(bskt[\"Quantity\"])\n})\n# sum all values in the perItemTotal\nsum(perItemTotal)\n\n[1] 14\n\n\nA quick note on function calls in the apply family:\nIf a function call only has one argument, they can be done in three ways. 1. sapply(X, function(x) { ... }) if function is not predefined 2. sapply(X, function) if function is predefined 3. sapply(X, function(x)) if function is predefined\nOption two is most common for built-in functions such as sum or as.numeric, but can be used with any function."
  },
  {
    "objectID": "posts/2022-03-14-writing-faster-r-with-vectorization-and-the-apply-family.html#vector-operations",
    "href": "posts/2022-03-14-writing-faster-r-with-vectorization-and-the-apply-family.html#vector-operations",
    "title": "Writing Faster R With Vectorization and the Apply Family",
    "section": "Vector Operations",
    "text": "Vector Operations\nVector operations are not a function like the apply family or a for loop, but rather a feature of the R language. Instead of operating on a vector one item at a time, R is able to do an operation on the entire vector in one line of code. Back to the basket example again, we know that the per item total is the PricePerUnit and Quantity multiplied together, and then we get the grand total by summing all of those values.\n\n# take the sum of multiplying PerPriceUnit and Quantity to get total cost\nsum(basket$PricePerUnit * basket$Quantity)\n\n[1] 14"
  },
  {
    "objectID": "posts/2022-03-14-writing-faster-r-with-vectorization-and-the-apply-family.html#for-loop-1",
    "href": "posts/2022-03-14-writing-faster-r-with-vectorization-and-the-apply-family.html#for-loop-1",
    "title": "Writing Faster R With Vectorization and the Apply Family",
    "section": "for loop",
    "text": "for loop\nfor loops in R should be a last resort. They are much slower compared to the apply family and vectorized code. They may be helpful when each iteration relies on the iteration before it, although then you might want to look into a recursive function if possible. You might find a for loop useful if you need to run the same block of code multiple times or iterate over elements of an object in a non-standard way such as every other item. Any code that can be written with an apply function or a vector operation can be written in a for loop."
  },
  {
    "objectID": "posts/2022-03-14-writing-faster-r-with-vectorization-and-the-apply-family.html#apply-family-1",
    "href": "posts/2022-03-14-writing-faster-r-with-vectorization-and-the-apply-family.html#apply-family-1",
    "title": "Writing Faster R With Vectorization and the Apply Family",
    "section": "apply family",
    "text": "apply family\nThe apply family should be used when you want to operate on each element of an object, but treat them individually. This might present as a list with vectors of differing lengths for each item or if you want a specific type of output. Any vector operation can be written as an apply statement, but not all for loops can be converted."
  },
  {
    "objectID": "posts/2022-03-14-writing-faster-r-with-vectorization-and-the-apply-family.html#vector-operations-1",
    "href": "posts/2022-03-14-writing-faster-r-with-vectorization-and-the-apply-family.html#vector-operations-1",
    "title": "Writing Faster R With Vectorization and the Apply Family",
    "section": "Vector Operations",
    "text": "Vector Operations\nVector operations are the gold standard. They are fast and can be used in many cases, but not all. Most common use cases will be on vectors or columns of a data.frame. Many base functions such as sum and as.numeric are already vectorized. Many but not all for loops and apply functions can be written as vectorized operations."
  },
  {
    "objectID": "posts/2022-03-14-writing-faster-r-with-vectorization-and-the-apply-family.html#building-the-input",
    "href": "posts/2022-03-14-writing-faster-r-with-vectorization-and-the-apply-family.html#building-the-input",
    "title": "Writing Faster R With Vectorization and the Apply Family",
    "section": "Building the input",
    "text": "Building the input\nRather than use the simple shopping basket example from before, I’ve written a small function that takes a data.frame of red, green, and blue values and adds a new column with the corresponding hex code.\n\n# create a vector of the possible hex code values (0-9 and A-F)\nhex <- c(0:9, LETTERS[1:6])\n\n# set the seed\nset.seed(2022)\n# pick the number of rows\nrows <- 10^4\n# create a data.frame of rgb values\ndf <- data.frame(\"red\" = sample(0:255, rows, replace = TRUE), \n                 \"green\" = sample(0:255, rows, replace = TRUE),\n                 \"blue\" = sample(0:255, rows, replace = TRUE))\n\nAnd the resulting data should look like this:\n\n\n\nred\ngreen\nblue\n\n\n\n\n227\n18\n84\n\n\n178\n245\n26\n\n\n205\n219\n176\n\n\n54\n236\n205\n\n\n74\n252\n67\n\n\n195\n116\n122\n\n\n\nWe’ve also created a vector of values that can go in a hex code with numbers 0–9 and letters A-F."
  },
  {
    "objectID": "posts/2022-03-14-writing-faster-r-with-vectorization-and-the-apply-family.html#creating-the-conversion-function",
    "href": "posts/2022-03-14-writing-faster-r-with-vectorization-and-the-apply-family.html#creating-the-conversion-function",
    "title": "Writing Faster R With Vectorization and the Apply Family",
    "section": "Creating the conversion function",
    "text": "Creating the conversion function\nI used this website for the math behind my functions. In essence, you divide each number by 16 and round down and the resulting number corresponds to a position in hex. You then take the remainder of the division and get the hex value that that number corresponds to. If our value is 227, then our first hex code is 227/16 would round down to 14 and the remainder would be 3. Because vectors in R start at position 1, we add one to both for 15 and 4. The corresponding values in hex are E and 3 and so the hex pair for 227 is E3."
  },
  {
    "objectID": "posts/2022-03-14-writing-faster-r-with-vectorization-and-the-apply-family.html#implementing-the-conversion-function",
    "href": "posts/2022-03-14-writing-faster-r-with-vectorization-and-the-apply-family.html#implementing-the-conversion-function",
    "title": "Writing Faster R With Vectorization and the Apply Family",
    "section": "Implementing the conversion function",
    "text": "Implementing the conversion function\n\nIn a for loop\n\n# iterate over each row in df\nfor(r in 1:nrow(df)) {\n  # get a value for each position in the hex code\n  # first pair\n  h1 <- hex[floor(df$red[r] / 16) + 1]\n  h2 <- hex[df$red[r] %% 16 + 1]\n  \n  # second pair\n  h3 <- hex[floor(df$green[r] / 16) + 1]\n  h4 <- hex[df$green[r] %% 16 + 1]\n\n  # third pair\n  h5 <- hex[floor(df$blue[r] / 16) + 1]\n  h6 <- hex[df$blue[r] %% 16 + 1]\n  \n  # assemble the values using `paste0` and assign it to the `hex` column for \n  # the corresponding row\n  df$hex[r] <- paste0(\"#\", h1, h2, h3, h4, h5, h6)\n}\n\n\n\nIn an apply function\n\ndf <- df[, c(\"red\", \"green\", \"blue\")]\n# create the rgbToHex function that takes a named vector and returns a hex code\nrgbToHex <- function(x) {\n  # get a value for each position in the hex code\n  # first pair\n  h1 <- hex[floor(x[\"red\"] / 16) + 1]\n  h2 <- hex[x[\"red\"] %% 16 + 1]\n  \n  # second pair\n  h3 <- hex[floor(x[\"green\"] / 16) + 1]\n  h4 <- hex[x[\"green\"] %% 16 + 1]\n\n  # third pair\n  h5 <- hex[floor(x[\"blue\"] / 16) + 1]\n  h6 <- hex[x[\"blue\"] %% 16 + 1]\n  \n  # assemble and return the hex code\n  paste0(\"#\", h1, h2, h3, h4, h5, h6)\n}\n# call `rgbToHex` and apply it to each row in df\ndf$hex <- apply(df, 1, rgbToHex)\n\n\n\nIn a vectorized function\n\n# paste the calculated hex codes into the new `hex` column in df\ndf$hex <- paste0(\"#\", \n                 hex[floor(df$red / 16) + 1],\n                 hex[df$red %% 16 + 1],\n                 hex[floor(df$green / 16) + 1],\n                 hex[df$green %% 16 + 1],\n                 hex[floor(df$blue / 16) + 1],\n                 hex[df$blue %% 16 + 1])\n\n\n\nThe results\n\n\n\nred\ngreen\nblue\nhex\n\n\n\n\n227\n18\n84\n#E31254\n\n\n178\n245\n26\n#B2F51A\n\n\n205\n219\n176\n#CDDBB0\n\n\n54\n236\n205\n#36ECCD\n\n\n74\n252\n67\n#4AFC43\n\n\n195\n116\n122\n#C3747A"
  },
  {
    "objectID": "posts/2022-03-14-writing-faster-r-with-vectorization-and-the-apply-family.html#running-the-benchmark",
    "href": "posts/2022-03-14-writing-faster-r-with-vectorization-and-the-apply-family.html#running-the-benchmark",
    "title": "Writing Faster R With Vectorization and the Apply Family",
    "section": "Running the benchmark",
    "text": "Running the benchmark\nI’ve simplified the for loop and apply implementations a little bit to better match the vectorized function. This way we have a better comparison between the three. Your benchmark results may be a little different because it is a little dependent on your computer.\n\nrows <- 10^4\nhex <- c(0:9, LETTERS[1:6])\n\nset.seed(2022)\ndt <- data.frame(\"red\" = sample(0:255, rows, replace = TRUE), \n                 \"green\" = sample(0:255, rows, replace = TRUE),\n                 \"blue\" = sample(0:255, rows, replace = TRUE))\n\nrbenchmark::benchmark(\n  \"for loop\" = {\n    df <- dt\n    for (r in 1:nrow(df)) {\n      df$hexFor[r] <- paste0(\"#\", \n                             hex[floor(df$red[r] / 16) + 1],\n                             hex[df$red[r] %% 16 + 1],\n                             hex[floor(df$green[r] / 16) + 1],\n                             hex[df$green[r] %% 16 + 1],\n                             hex[floor(df$blue[r] / 16) + 1],\n                             hex[df$blue[r] %% 16 + 1]\n                             )\n    }\n  },\n  \"apply\" = {\n    df <- dt\n    rgbToHex <- function(x) {\n      paste0(\"#\",\n             hex[floor(x[\"red\"] / 16) + 1],\n             hex[x[\"red\"] %% 16 + 1],\n             hex[floor(x[\"green\"] / 16) + 1],\n             hex[x[\"green\"] %% 16 + 1],\n             hex[floor(x[\"blue\"] / 16) + 1],\n             hex[x[\"blue\"] %% 16 + 1]\n             )\n    }\n    df$hexApply <- apply(df, 1, rgbToHex)\n  },\n  \"vector\" = {\n    df <- dt\n    df$hexVector <- paste0(\"#\",\n                           hex[floor(df$red / 16) + 1],\n                           hex[df$red %% 16 + 1],\n                           hex[floor(df$green / 16) + 1],\n                           hex[df$green %% 16 + 1],\n                           hex[floor(df$blue / 16) + 1],\n                           hex[df$blue %% 16 + 1]\n                           )\n  },\n  replications = 10, order = \"relative\"\n) -> benches\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntest\nreplications\nelapsed\nrelative\nuser.self\nsys.self\nuser.child\nsys.child\n\n\n\n\nvector\n10\n0.026\n1.000\n0.025\n0.000\n0\n0\n\n\napply\n10\n0.536\n20.615\n0.530\n0.006\n0\n0\n\n\nforloop\n10\n1.569\n60.346\n1.252\n0.317\n0\n0\n\n\n\nThe important column is relative as that shows a comparison between the three with the quickest function given a value of 1. Using an apply function took roughly 20x longer and a for loop roughly 60x longer than using a vectorized function.\n\n\nAll code used in this article is available here. If you want to see more from me, check out my GitHub or guslipkin.github.io. If you want to hear from me, I’m also on Twitter @guslipkin.\n\nGus Lipkin is a Data Scientist, Business Analyst, and occasional bike mechanic"
  },
  {
    "objectID": "posts/2022-02-23-making-pretty-excel-files-in-r.html",
    "href": "posts/2022-02-23-making-pretty-excel-files-in-r.html",
    "title": "Making Pretty Excel Files in R",
    "section": "",
    "text": "Intro\nIt’s a tale as old as time. Your boss gave you a bunch of Excel files and you painstakingly made a bot that will import and display them in a Shiny dashboard. Proud of your work, you take it to your boss and they say “I don’t know what a ‘Shiny’ is, can’t you just give me one of those Excels back?” openxlsx makes this easy.\nToday we’re going to recreate an existing workbook with openxlsx. To get started, I made a small .xlsx file for us to work with that can be downloaded here. It’s an attendance list and some notes on supplies you’ll need for a company barbecue. Feel free to get familiar with it then come back here when you’re ready.\n\n\n\n\n\n\n\n(a) The attendance sheet\n\n\n\n\n\n\n\n(b) The supplies sheet\n\n\n\n\nFigure 1: A preview of the Attendance and Supplies sheets\n\n\n\n\n\nReading an Existing Workbook\nAs usual, the first thing to do is load our library with library(openxlsx). We can try and load the workbook, the Excel file, with read.xlsx, but for now we’re going to use loadWorkbook. This loads a workbook object and exposes some workbook properties to us rather than just the raw data like with read.xlsx.\n\n# load openxlsx\nlibrary(openxlsx)\n# get the sheet names\nbbq <- loadWorkbook(filePath)\nnames(bbq)\n\n# load the sheets and preview them\nattendance <- readWorkbook(bbq, \"Attendance\")\nhead(attendance)\n\nsupplies <- readWorkbook(bbq, sheet = \"Supplies\")\nhead(supplies)\n\n[1] “Attendance” “Supplies”\n\n\n\n\nName\nRSVPed\nStatus\nFoodPreference\n\n\n\n\n1\nMasud Durga\nTRUE\nNo\nNA\n\n\n2\nStanislav Zillah\nTRUE\nYes\nHotdog\n\n\n3\nJoaquina Aristide\nFALSE\nNA\nNA\n\n\n4\nIuppiter Dieu\nTRUE\nYes\nHotdog\n\n\n5\nHari Evgenios\nTRUE\nYes\nHamburger\n\n\n6\nShaina Gwenaelle\nTRUE\nYes\nHotdog\n\n\n\n\nThe attendance data.frame\n\n\n\n\n\nSupplyType\nQuantity\nPerPackage\nPackagesNeeded\nLeftover\n\n\n\n\n1\nHotdogs\n34\n10\n4\n6\n\n\n2\nHotdog buns\nNA\n8\n5\n6\n\n\n3\nHamburgers\n36\n6\n6\n0\n\n\n4\nHamburger buns\nNA\n8\n5\n4\n\n\n\n\nThe supplies data.frame\n\nBecause we loaded the data as a workbook object, we can use getStyles to load the styles and preview them. Unfortunately, the styles can’t pull conditional formatting and don’t keep track of which cells use which styles. By cross referencing the list of styles and bbq.xlsx, we can identify some styles to use and them assign them each to a variable.\n\n# getStyles and set them appropriately\nstyles <- getStyles(bbq)\nstyles\n\n# doesn't work for colors because those are conditional formatting\nheaderStyle <- styles[[1]]\nnumberStyle <- styles[[7]]\n\nI’ve chosen to only show the first two items from the styles list here.\n[[1]]\nA custom cell style. \n\n Cell formatting: GENERAL \n Font name: Calibri \n Font size: 14 \n Font colour: 1 \n Font decoration: BOLD \n \n\n[[2]]\nA custom cell style. \n\n Cell formatting: GENERAL \n Cell horz. align: center\n\n\n\nCreating a Workbook\nFirst thing we have to do is create a workbook object that we’ll call wb. We can quickly preview it by just typing wb into our chunk or the console.\n\n# create workbook and check contents\nwb <- createWorkbook()\nwb\n\nA Workbook object.\n \nWorksheets:\n No worksheets attached\n\n\nWe’re going to make the Supplies sheet first as it’s a little bit easier. We first add a new worksheet named Supplies to the workbook, then we can write the relevant data to that sheet along with styling our column headers using headerStyle from earlier.\n\n# create the supplies sheet and check for it\naddWorksheet(wb = wb, sheetName = \"Supplies\")\n# write supplies to the worksheet using headerStyle\nwriteData(wb = wb, sheet = \"Supplies\", x = supplies, headerStyle = headerStyle)\n\n\n\nAdding Styles\nAll of the numbers in the Supplies sheet are centered both horizontally and vertically. We can achieve this by adding the numberStyle from before to those cells. rows and cols both start at 2 because row one is the header row and column one is the supply type. rows goes to 5 because there are 4 rows of numbers (remember the header row) and cols goes to 5 because there are 4 columns of numbers. gridExpand = TRUE makes sure that all cell reference combinations possible with rows and cols are used, rather than doing an entire row or column.\n\n# add numberStyle\naddStyle(wb = wb, sheet = \"Supplies\", style = numberStyle, rows = 2:5, \n         cols = 2:5, gridExpand = TRUE)\n\nIf we go back to our data in R, the Quantity for Hotdog buns and Hamburger buns is empty. A bit further back, we see that that’s because those cells were merged with the Quantity of Hotdogs and Hamburgers respectively. We can replicate this using mergeCells. Unlike addStyle, we don’t need to use gridExpand to merge all the cells as it is implied. cols will be 2 for both and we want rows 2 and 3 for Hotdogs and rows 4 and 5 for Hamburgers.\n\n# merge the hamburger and hotdog quantity cells\nmergeCells(wb = wb, sheet = \"Supplies\", cols = 2, rows = 2:3)\nmergeCells(wb = wb, sheet = \"Supplies\", cols = 2, rows = 4:5)\n\nOur last step on this worksheet is to set the column widths to auto. We again need to specify cols and can just do 1:5 so that all columns are affected.\n\n# set column widths to auto\nsetColWidths(wb = wb, sheet = \"Supplies\", cols = 1:5, widths = \"auto\")\n\nOu Supplies sheet is now complete, but we’re not going to write it just yet because we still need to do the Attendance sheet.\nLike before, we first add the Attendance worksheet and write the data to it.\n\n# create the attendance sheet and check for it\naddWorksheet(wb = wb, sheetName = \"Attendance\")\n\n# write attendance to the worksheet using the same headerStyle from before\nwriteData(wb = wb, sheet = \"Attendance\", x = attendance, \n          headerStyle = headerStyle)\n\n\n\n\nConditional Formatting\nThe RSVPed and Status columns each have some conditional formatting. We can reuse the color formatting from the RSVPed column on the Status column, so we’re going to separate the color style from the alignment style. It was easy to see how many rows we have in the Supplies sheet but not here so we’re going to create a new variable that has the rowNumbers. Again, we start on row 2 because of the header row and will end at our last data row plus 1.\n\n# create color styles for rsvp and status\ngoodStyle <- createStyle(fontColour = \"#006100\", bgFill = \"#C6EFCE\")\nbadStyle <- createStyle(fontColour = \"#9C0006\", bgFill = \"#FFC7CE\")\n# create center style for rsvp column\ncenterStyle <- createStyle(halign = \"center\")\n\n# create a variable of row numbers\nrowNumbers <- seq(2, nrow(attendance) + 1, by = 1)\n\nOur first step is to center the values in the RSVPed column with an addStyle. Next, while we could manually color each cell using a for loop, it’s more efficient to use conditionalFormatting. This also has the added bonus of showing in Excel and responding to any changes. The rule argument may be a little strange, and that’s because it must match how the same formatting rule would be written in Excel. In this case, we use our top-leftmost cell as the reference cell in the rule, B2, then we check if it is TRUE or FALSE. When the rule is applied down the cells in column B, the row number will change to match the current row.\n\n# center the column values\naddStyle(wb = wb, sheet = \"Attendance\", \n         style = centerStyle, cols = 2, rows = rowNumbers)\n\n# IF `RSVPed` is TRUE, set it to green. IF FALSE, set it to red\nconditionalFormatting(wb = wb, sheet = \"Attendance\", cols = 2, \n                      rows = rowNumbers, rule = \"B2==TRUE\", style = goodStyle)\nconditionalFormatting(wb = wb, sheet = \"Attendance\", cols = 2, \n                      rows = rowNumbers, rule = \"B2==FALSE\", style = badStyle)\n\nThe Status column is very similar to the RSVPed column, but we add a style for Tentative responses and then need a third conditionalFormatting. The newest part here is in the rule argument. We need to put quotes around Yes so that Excel knows that it is a string and need to use \\\" so that R knows that the quote is part of the string. Once our formatting has been applied, we set the column widths as we did before.\n\n# add style for status and tentative\nmaybeStyle <- createStyle(fontColour = \"#9C6500\", bgFill = \"#FFEB9C\")\n\nconditionalFormatting(wb = wb, sheet = \"Attendance\", cols = 3, \n                      rows = rowNumbers, rule = \"C2==\\\"Yes\\\"\", \n                      style = goodStyle)\nconditionalFormatting(wb = wb, sheet = \"Attendance\", cols = 3, \n                      rows = rowNumbers, rule = \"C2==\\\"No\\\"\", \n                      style = badStyle)\nconditionalFormatting(wb = wb, sheet = \"Attendance\", cols = 3, \n                      rows = rowNumbers, rule = \"C2==\\\"Tentative\\\"\", \n                      style = maybeStyle)\n\n# set column widths to auto\nsetColWidths(wb = wb, sheet = \"Attendance\", cols = 1:4, widths = \"auto\")\n\n\n\n\nWriting the Workbook\nThe last thing we need to do is reorder the worksheets so that Attendance is first because when we created the workbook in R, we created the Supplies worksheet first. Unfortunately, worksheetOrder only supports integer vectors. We can check our worksheet numbers by calling the object again through either the chunk or console. Then we set the worksheet order and save the workbook to an .xlsx file.\n\n# check the workbook sheet order\nwb\n\nA Workbook object.\n \nWorksheets:\n Sheet 1: \"Supplies\"\n \n    Custom column widths (column: width)\n      1: auto, 2: auto, 3: auto, 4: auto, 5: auto \n \n\n Sheet 2: \"Attendance\"\n \n    Custom column widths (column: width)\n      1: auto, 2: auto, 3: auto, 4: auto \n \n\n \n Worksheet write order: 1, 2\n Active Sheet 1: \"Supplies\" \n    Position: 1\n\n# change the order\nworksheetOrder(wb) <- c(2, 1)\n\n# save the workbook\nsaveWorkbook(wb, outputPath, overwrite = TRUE)\n\nIf we open the new file, we can see that they are nearly identical. The biggest difference between the two is that the original used formulas to calculate the values in Supplies.\nIf you did want to take it a step further and use those instead, the writeFormula function is your friend. In any case, I highly encourage everyone to at least skim through the openxlsx documentation here because it has so much to offer to help streamline Excel file generation.\n\nAll the code for this article is available here. If you want to see more from me, check out my GitHub or guslipkin.github.io. If you want to hear from me, I’m also on Twitter @guslipkin.\n\nGus Lipkin is a Data Scientist, Business Analyst, and occasional bike mechanic"
  },
  {
    "objectID": "posts/2022-02-16-grouped-and-stacked-bar-charts-in-r.html",
    "href": "posts/2022-02-16-grouped-and-stacked-bar-charts-in-r.html",
    "title": "Grouped and Stacked Bar Charts in R",
    "section": "",
    "text": "Intro\nSometimes you have a chart that looks like one of these. You have a grouped chart that shows one thing and a stacked chart that shows another. But you really want to show the continent of origin and the condition in one chart.\n\n\n\n\n\n\n\n(a) A grouped bar chart\n\n\n\n\n\n\n\n(b) A stacked bar chart\n\n\n\n\nFigure 1: A grouped bar chart and a stacked bar chart\n\n\nMaybe the chart you want looks a lot like this:\n\n\n\nThe chart that we will learn to build\n\n\n\n\n\nCreating the Data\nFirst we load ggplot2 so we can make our charts. Then we make some data and preview it. set.seed(2022) makes sure that our data is the same every time.\n\nlibrary(ggplot2)\n\nset.seed(2022)\nspecie <- c(rep(\"sorgho\", 6), rep(\"poacee\", 6), \n            rep(\"banana\", 6), rep(\"triticum\", 6))\ncondition <- rep(c(\"normal\" , \"stress\" , \"N2\") , 8)\ncontinent <- rep(c(\"Europe\", \"Africa\", \"Asia\", \"South America\",          \n                   \"North America\", \"Australia\"), 4)\nvalue <- abs(rnorm(24 , 0 , 15))\ndata <- data.frame(specie, condition, continent, value)\nhead(data)\n\n\nCreating the data\n\n\n\n\n\nspecie\ncondition\ncontinent\nvalue\n\n\n\n\n1\nsorgho\nnormal\nEurope\n33.2982559377826\n\n\n2\nsorgho\nstress\nAfrica\n7.4199245988712\n\n\n3\nsorgho\nN2\nAsia\n52.3689859681817\n\n\n4\nsorgho\nnormal\nSouth America\n4.85975695583929\n\n\n5\nsorgho\nstress\nNorth America\n6.84424418650998\n\n\n6\nsorgho\nN2\nAustralia\n6.74199859289553\n\n\n\n\nPreviewing the data\n\n\n\n\nNot Quite Right\nOur first instinct might be to throw both charts together using grid.arrange from the gridextra package. While this does show the information we want, it’s not pretty and doesn’t show the data the way we want it to.\n\none <- ggplot(data) +\n  geom_bar(aes(x = specie, y = value, fill = condition), \n           position = \"dodge\", stat = \"identity\")\ntwo <- ggplot(data) +\n  geom_bar(aes(x = specie, y = value, fill = continent), \n           position = \"stack\", stat = \"identity\")\ngridExtra::grid.arrange(one, two, nrow = 2)\n\n\n\n\nNot sure what to do, we come up with lots of plots that are almost right, but not quite.\n\n\n\n\n\n\n\n(a)\n\n\n\n\n\n\n\n(b)\n\n\n\n\n\n\n\n(c)\n\n\n\n\nFigure 2: Three attempts at making a grouped and stacked bar chart\n\n\nThe last one looks like it could be promising. How did we do it?\n\nggplot(data) +\n  geom_bar(aes(x = condition, y = value, fill = continent),\n           position = \"stack\",\n           stat = \"identity\") +\n  facet_wrap(~ specie)\n\nWe use ggplot to set up the pipeline, geom_bar to create the bar chart, and then facet_wrap is what gives us the four separate charts in one, with one mini-chart for each species. If we can move the charts to be side-by-side, we’ll be a lot closer to the desired outcome. We can use facet_grid instead of facet_wrap to accomplish that.\n\nggplot(data) +\n  geom_bar(aes(x = condition, y = value, fill = continent),\n           position = \"stack\",\n           stat = \"identity\") +\n  facet_grid(~ specie)\n\n\n\n\nUsing facet_grid() to show multiple plots next to each other\n\n\n\n\nThis looks much better, but we want it to look like one cohesive plot, rather than four smaller plots.\n\n\n\nThe Final Product\nI’m going to show you the code that does it, then walk through it so everything makes sense.\n\nggplot(data) +\n  geom_bar(aes(x = condition, y = value, fill = continent),\n           position = \"stack\",\n           stat = \"identity\") +\n  facet_grid(~ specie, switch = \"x\") +\n  theme(strip.placement = \"outside\",\n        strip.background = element_rect(fill = NA, color = \"white\"),\n        panel.spacing = unit(-.01,\"cm\"))\n\n\n\n\nThe graph that we came here for\n\n\n\n\nThis looks pretty good and is exactly what we wanted. Like the charts before, we get 90% of the way there with ggplot, geom_bar, and facet_grid. The additions here are the switch = \"x\" argument in facet_grid, which moves the group panel with the species from the top of the chart to the bottom. Moving the strip.placement outside makes sure that the conditions are listed between the species and the chart. Making strip.background empty with a white border allows the group panel with the species to blend in with the white background of the chart. Lastly, changing the panel.spacing to -.01 removes the small gap between each panel so that the chart appears to be one cohesive unit.\n\nThe code for all the charts in this article is available here. If you want to see more from me, check out my GitHub or guslipkin.github.io. If you want to hear from me, I’m also on Twitter @guslipkin.\n\nGus Lipkin is a Data Scientist, Business Analyst, and occasional bike mechanic"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Hi There 👋",
    "section": "",
    "text": "I’m Gus, a Business Analyst with a few years’ experience. I’d like to show you what I do.\nYou can also find me on Twitter @guslipkin or on Medium also @guslipkin."
  },
  {
    "objectID": "index.html#data-focused-projects",
    "href": "index.html#data-focused-projects",
    "title": "Hi There 👋",
    "section": "Data Focused Projects",
    "text": "Data Focused Projects"
  },
  {
    "objectID": "index.html#economic-analysis-focused-projects",
    "href": "index.html#economic-analysis-focused-projects",
    "title": "Hi There 👋",
    "section": "Economic Analysis Focused Projects",
    "text": "Economic Analysis Focused Projects"
  },
  {
    "objectID": "index.html#software-development",
    "href": "index.html#software-development",
    "title": "Hi There 👋",
    "section": "Software Development",
    "text": "Software Development"
  },
  {
    "objectID": "index.html#other-projects",
    "href": "index.html#other-projects",
    "title": "Hi There 👋",
    "section": "Other Projects",
    "text": "Other Projects"
  },
  {
    "objectID": "index.html#consulting",
    "href": "index.html#consulting",
    "title": "Hi There 👋",
    "section": "Consulting",
    "text": "Consulting"
  },
  {
    "objectID": "capstone.html",
    "href": "capstone.html",
    "title": "Patient Readmission Rates with Tallahassee Memorial Healthcare",
    "section": "",
    "text": "Previous\n\n\n Next"
  },
  {
    "objectID": "capstone.html#demographics",
    "href": "capstone.html#demographics",
    "title": "Patient Readmission Rates with Tallahassee Memorial Healthcare",
    "section": "Demographics",
    "text": "Demographics"
  },
  {
    "objectID": "capstone.html#story",
    "href": "capstone.html#story",
    "title": "Patient Readmission Rates with Tallahassee Memorial Healthcare",
    "section": "Story",
    "text": "Story\n\nAll stories are fictional and creations of the author"
  },
  {
    "objectID": "capstone.html#discharge-survey",
    "href": "capstone.html#discharge-survey",
    "title": "Patient Readmission Rates with Tallahassee Memorial Healthcare",
    "section": "Discharge Survey",
    "text": "Discharge Survey\nPlease answer this survey based on the above narrative\n\n\nDuring this hospital stay, did you need help from nurses or other hospital staff in getting to the bathroom or in using a bed pan?\n\nYes No  \n\nIn general, how would you rate your overall health?\n\nPoor Fair Good Very Good Excellent  \n\nBefore giving you any new medicine, how often did hospital staff tell you what the medicine was for?\n\nNever Rarely Sometimes Often Always  \n\nWhen I left the hospital, I clearly understood the purpose for taking each of my medications?\n\nNever Seldom Sometimes Often Always  \n\nDuring this hospital stay, were you admitted to this hospital through the emergency room?\n\nYes No   Submit your survey Reset your survey"
  },
  {
    "objectID": "capstone.html#your-results",
    "href": "capstone.html#your-results",
    "title": "Patient Readmission Rates with Tallahassee Memorial Healthcare",
    "section": "Your Results",
    "text": "Your Results\n\nYour results will be here!"
  },
  {
    "objectID": "about.html#a-brief-history",
    "href": "about.html#a-brief-history",
    "title": "About Me",
    "section": "A Brief History",
    "text": "A Brief History\n\n\nI was born and raised in Massachusetts about twenty minutes west of Boston. In elementary school, I spent my summers at circus camp where I learned to ride a unicycle, walk on stilts, a variety of other skills generally requiring a large soft pad at the bottom, and failing to figure out how to juggle. In fourth grade, I got so frustrated that I did a project on juggling so that I knew exactly what to do, but I’ve still never been able to get my hands to move the right way. During the fall and winter months, I did ballet and danced in a production of The Nutcracker. It was during our downtime then that I first learned to solve a Rubik’s cube. In middle school, I took part in an archery club after school and eventually began to mentor younger students and carried that on through high school. My junior year of high school, I help start the VEX robotics team and went to World Championships. I also became involved in TV production and joined the local channel.\n\n\n\n  A backstage photo from The Nutcracker (2009)\n\n\n\n\n  Working at Starbucks (2017)\n\n\n\nAfter graduating high school in 2015, I launched the archery program at a summer camp in Canada and designed and built a modular Gaga pit. (Gaga is sort of like a dodgeball battle-royale that you may recognize from an episode of Bob’s Burgers. I spent the next few years working at a Starbucks where I won my store’s Barista Championship in 2018 and 2019. During my time with the company, I quickly learned all the recipes and became one of the fastest and most reliable baristas in the store. Because of my knowledge and reliablity, I was asked to become a Barista Trainer and helped train baristas, supervisors, and store managers from across the district.\n\n\n I came to Florida Poly during Fall 2018 and the rest, as they say, is history. You can learn more about my time at Florida Poly and projects here and see my resume here."
  },
  {
    "objectID": "about.html#selected-interests",
    "href": "about.html#selected-interests",
    "title": "About Me",
    "section": "Selected Interests",
    "text": "Selected Interests\n\nBiking 🚴‍♂️🚵‍♂️\nMany years ago, there was a summer that I was on my bike so much that I didn’t even take my helmet off for meals. While my passion for biking certainly hasn’t waned, I don’t have as much time as I did when my biggest worries were making it home before dark. Until I moved to Florida, I volunteered for many years with the Pan-Mass Challenge, first as a tire pumper and then a mechanic as I developed my skills. More recently, I started a small mountain biking YouTube channel that I update when I can. I also participated in the 2021 Horrible Hundred and it was exactly as horrible as you might imagine.\n\n\nSpeedsolving\nWhen someone sees you with a Rubik’s cube and asks if you can solve it, they almost never expect to be told, “Give me 15 seconds” and then presented with a solved cube. I have a relatively small collection of puzzles and enjoy the zen mindset that can be found from practicing. I’m rather pleased with my competition results and have some of my solves on camera on a YouTube channel. I’m hoping to get out to competitions a bit more so I can update everyone with all the progress I’ve made. Within the community, I served on the WCA Communications Committee for a brief period, have helped staff a variety of competitions, and even organized my own competition in my hometown called Framingham Frozen Fingers."
  },
  {
    "objectID": "about.html#recommendations-from-friends",
    "href": "about.html#recommendations-from-friends",
    "title": "About Me",
    "section": "Recommendations from Friends",
    "text": "Recommendations from Friends\n\n\n“Gus is one of the most dependable and consistent people I have ever known.” – Melia R\n\n\n“You can always rely on Gus to burn his food” – Izzy Z\n\n\n“This is a guy that knows the guy you need for whatever it is you need” – Tucker M-S\n\n\n“Lemme think about it” – Macy L\n\n\n“Gus Lipkin, in the many the years I’ve known him, has enough resourcefulness and preparation skills in him to do the work of a dozen people” – Chris H"
  },
  {
    "objectID": "presentations/cat_simulator_2019.html",
    "href": "presentations/cat_simulator_2019.html",
    "title": "Cat Simulator 2019",
    "section": "",
    "text": "Previous\n\n\n Next"
  },
  {
    "objectID": "presentations/trader_joes_cultural_marketing_plan.html",
    "href": "presentations/trader_joes_cultural_marketing_plan.html",
    "title": "Trader Joe’s Cultural and Marketing Plan",
    "section": "",
    "text": "Previous\n\n\n Next"
  },
  {
    "objectID": "presentations/spreadsheet_guide.html",
    "href": "presentations/spreadsheet_guide.html",
    "title": "Gus’ Good Spreadsheet Guide",
    "section": "",
    "text": "Previous\n\n\n Next"
  },
  {
    "objectID": "presentations/tutoring_at_poly.html",
    "href": "presentations/tutoring_at_poly.html",
    "title": "Improving Tutoring at Florida Poly",
    "section": "",
    "text": "Previous\n\n\n Next"
  },
  {
    "objectID": "presentations/disney_world_ride_wait_times.html",
    "href": "presentations/disney_world_ride_wait_times.html",
    "title": "Disney World ride wait times",
    "section": "",
    "text": "Previous\n\n\n Next"
  },
  {
    "objectID": "presentations/covid_time_series_gis.html",
    "href": "presentations/covid_time_series_gis.html",
    "title": "Investigating a relationship between climate variables and the spread of COVID-19",
    "section": "",
    "text": "🦠 Print a copy"
  },
  {
    "objectID": "presentations/covid_time_series_gis.html#watch-me-present",
    "href": "presentations/covid_time_series_gis.html#watch-me-present",
    "title": "Investigating a relationship between climate variables and the spread of COVID-19",
    "section": "Watch me present",
    "text": "Watch me present"
  },
  {
    "objectID": "dewey.html",
    "href": "dewey.html",
    "title": "Gus Lipkin's Awesome Website",
    "section": "",
    "text": "Install Process\n\ninstall.packages(\"devtools\")\ndevtools::install_github(\"guslipkin/dewey\")\n\n\n\nregsearch\n(data, dependent, independent, minvar = 1, maxvar, family, topN = 0, interactions = FALSE, multi = FALSE, ...)\nAn exhaustive search regression built on base R\n\n\nifelsedata\n(x, y, arg = NULL, matchCols = FALSE)\nFast data.frame comparisons at the cell level\n\n\ndiffFill\n(x, lag = 1, differences = 1, ...)\nA wrapper for the base diff function that returns a data.frame of the same length as the input. Allows for vector input for lag or differences.\n\n\nlagMultiple\n(x, k = 1)\nAppropriately lags an input variable and returns a data.frame of the same length as the input. Allows for vector input for k."
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "My Blog",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nR\n\n\nR: tidyverse\n\n\nR: ggplot2\n\n\nR: tidytext\n\n\n\n\nThere are some useful tools for getting your plots exactly how you want them\n\n\n\n\n\n\nApr 14, 2022\n\n\nGus Lipkin\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nR\n\n\nR: tidyverse\n\n\nR: data.table\n\n\n\n\npivot_wider/dcast and pivot_longer/melt all make sense with a bit of explaining.\n\n\n\n\n\n\nMar 31, 2022\n\n\nGus Lipkin\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nR\n\n\nR: apply\n\n\n\n\nLearning when and how to use for loops, the apply family, and vectorization to write fast code in R\n\n\n\n\n\n\nMar 14, 2022\n\n\nGus Lipkin\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nR\n\n\nR: openxlsx\n\n\nExcel\n\n\n\n\nUsing the openxlsx package in R and RStudio to make formatted Excel files\n\n\n\n\n\n\nFeb 23, 2022\n\n\nGus Lipkin\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nR\n\n\nR: tidyverse\n\n\nR: ggplot2\n\n\n\n\nUsing R and ggplot2 to create stacked and grouped column charts\n\n\n\n\n\n\nFeb 16, 2022\n\n\nGus Lipkin\n\n\n\n\n\n\nNo matching items"
  }
]